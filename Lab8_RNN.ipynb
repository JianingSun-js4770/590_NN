{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RNN_Lab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"XOkBF0K6P6MC","executionInfo":{"status":"ok","timestamp":1606060335726,"user_tz":300,"elapsed":2016,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["#run it in google colab\n","import tensorflow as tf\n","import tensorflow.keras as tfk\n","import tensorflow.keras.layers as tfkl\n","from tensorflow.keras.models import Sequential\n","\n","from google.colab import drive\n","import numpy as np\n","import pandas as pd"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KdCU982WwzFo"},"source":["In this example, we're going to train a [CharRNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) on a body of Shakespearian text. Ultimtely, this is an unsuperived learning task. But similar to our previous explorations in unsupervised DL, we will use an unlabeled dataset and create many samples of labeled data that we can use with our familiar supervised loss functions. The result will be a model that has learned the statistical properties of the input text, and can then be considered a \"generative\" model of language because we can use it to generate synthetic passages of Shakespeare.  "]},{"cell_type":"code","metadata":{"id":"dX7qrncTRKN0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606061903792,"user_tz":300,"elapsed":23751,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"3e616aac-05f4-498f-8306-d62a37c66e2c"},"source":["drive.mount('/content/gdrive/') #connect with google drive"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6iek9QSARq1L","executionInfo":{"status":"ok","timestamp":1606061907899,"user_tz":300,"elapsed":891,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["file_path = \"/content/gdrive/My Drive/Colab Notebooks/shakespeare.txt\"\n","\n","with open(file_path,\"r\") as f:\n","  text = f.read()"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ie2LtLF4Vv6A"},"source":["We've loaded our Shakespeare text, let's take a look at a random snippet."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVFmTUsGWePe","executionInfo":{"status":"ok","timestamp":1606061910443,"user_tz":300,"elapsed":352,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"d7568ab7-d470-4c2e-8d70-92f240acab6b"},"source":["print(text[31600:32000])"],"execution_count":17,"outputs":[{"output_type":"stream","text":[" lies i' the second chamber?\n","  LADY MACBETH. Donalbain.\n","  MACBETH. This is a sorry sight.           [Looks on his hands.\n","  LADY MACBETH. A foolish thought, to say a sorry sight.\n","  MACBETH. There's one did laugh in 's sleep, and one cried,\n","      \"Murther!\"\n","    That they did wake each other. I stood and heard them,\n","    But they did say their prayers and address'd them\n","    Again to sleep.\n","  LADY MACB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qLXQHFUsW0xu"},"source":["We need to convert our text into numeric arrays, the next several blocks accomplish this.\n","\n","First, we'll create a mapping between characters and their numeric index. We'll also create the reverse mapping, which is useful."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkvcQEUASXQG","executionInfo":{"status":"ok","timestamp":1606015588566,"user_tz":300,"elapsed":511,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"e99726e1-04f5-4e55-e054-37a43aecbe11"},"source":["chars = sorted(list(set(text))) #vocabulary set\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["total chars: 75\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XexyPZdAXC0p"},"source":["Next, we'll create a training set of sub-sequences. Remember, we're trying to train a model to be able to predict the next chracter if it is given several characters of a subsequence. So we will create training pairs where each X is a fixed-length subsequences and each Y is the corresponding next letter in the text."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ej4RdC76S7RB","executionInfo":{"status":"ok","timestamp":1606015609123,"user_tz":300,"elapsed":424,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"4b3ad9a2-079e-4e88-8062-b083809e6804"},"source":["maxlen = 40\n","step = 3\n","sub_sequences = []\n","next_chars = []\n","for i in range(0, len(text) - maxlen, step): #i is the 1st word, maxlen is the input length;\n","    sub_sequences.append(text[i: i + maxlen]) #sub_sequences is the input characters\n","    next_chars.append(text[i + maxlen]) #next_chars is the output character\n","print('nb sequences:', len(sub_sequences))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["nb sequences: 38700\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVHru3qPWX8Z","executionInfo":{"status":"ok","timestamp":1606015793228,"user_tz":300,"elapsed":317,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"e0ffa2d3-6d01-4420-de9f-81a0162e901e"},"source":["k=300\n","print(\"(Sequence):\\n\" + sub_sequences[k])\n","print(\"\\n(Target Character): \\n\" + next_chars[k])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(Sequence):\n"," and other Apparitions\n","  Lords, Gentleme\n","\n","(Target Character): \n","n\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vD2QxlOAW8zQ"},"source":["Next we'll create one-hot vectors for our sub-sequences. The tensor we create here will be shaped as (num_sequences x sequence_length x alphabet_size)."]},{"cell_type":"code","metadata":{"id":"SfQRBmiNWehk","executionInfo":{"status":"ok","timestamp":1606016637933,"user_tz":300,"elapsed":1211,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["X = np.zeros((len(sub_sequences), maxlen, len(chars)), dtype=np.uint8 ) \n","# X: input dimension * dim of every input * character set (vocabulary set);\n","# 可以理解为有个matrix，每一行是一个输入，列数代表每个输入有多少字符，而第三维度即每个字符又以one-hot encoder表示\n","Y = np.zeros((len(sub_sequences), len(chars)), dtype=np.uint8)\n","# Y可以理解为：每一行是一个输出，由于每个输出是一个字符，所以可以直接以one-hot encoder来表示\n","for i, seq in enumerate(sub_sequences):\n","    for t, char in enumerate(seq): #t代表40个字符中已经遍历到哪个字符了\n","        X[i, t, char_indices[char]] = 1\n","        Y[i, char_indices[next_chars[i]]] = 1"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U4qxjsGDXLtb","executionInfo":{"status":"ok","timestamp":1606016754504,"user_tz":300,"elapsed":364,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"08dd0f49-a7fa-485b-a85b-a24dc1d3cdff"},"source":["X[0,0,:] \n","\"\"\"\n","0th input \n","-> 0th character (40 characters form an input) \n","-> all dimensions for one-hot vector (75 characters in total)\n","\"\"\""],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"423pgyKqXnE_","executionInfo":{"status":"ok","timestamp":1606016649633,"user_tz":300,"elapsed":379,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"999dc075-df38-4b56-fbca-47f81444488d"},"source":["Y[0]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"2dJrr1caYVnI"},"source":["Our RNN model will be quite simple."]},{"cell_type":"code","metadata":{"id":"95NSRVMpYGAT","executionInfo":{"status":"ok","timestamp":1606016822874,"user_tz":300,"elapsed":1019,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["char_rnn = Sequential()\n","char_rnn.add(tfkl.LSTM(128, input_shape=(maxlen, len(chars))))\n","char_rnn.add(tfkl.Dense(len(chars),activation=\"softmax\"))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4xdUMP_Y6iu","executionInfo":{"status":"ok","timestamp":1606016834494,"user_tz":300,"elapsed":359,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["char_rnn.compile(loss='categorical_crossentropy', optimizer=tfk.optimizers.RMSprop(lr=0.01))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGDTEd0GZFNk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606017329688,"user_tz":300,"elapsed":486899,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"326f9d1d-e579-4b9d-a6a2-35b0593ce02d"},"source":["char_rnn.fit(X,Y, epochs=20, batch_size=1024)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","38/38 [==============================] - 24s 623ms/step - loss: 3.3392\n","Epoch 2/20\n","38/38 [==============================] - 24s 621ms/step - loss: 2.7826\n","Epoch 3/20\n","38/38 [==============================] - 23s 613ms/step - loss: 2.2945\n","Epoch 4/20\n","38/38 [==============================] - 24s 624ms/step - loss: 2.0323\n","Epoch 5/20\n","38/38 [==============================] - 24s 622ms/step - loss: 1.8709\n","Epoch 6/20\n","38/38 [==============================] - 24s 630ms/step - loss: 1.7521\n","Epoch 7/20\n","38/38 [==============================] - 24s 622ms/step - loss: 1.6601\n","Epoch 8/20\n","38/38 [==============================] - 23s 612ms/step - loss: 1.5741\n","Epoch 9/20\n","38/38 [==============================] - 24s 626ms/step - loss: 1.5105\n","Epoch 10/20\n","38/38 [==============================] - 24s 623ms/step - loss: 1.4439\n","Epoch 11/20\n","38/38 [==============================] - 23s 613ms/step - loss: 1.3871\n","Epoch 12/20\n","38/38 [==============================] - 23s 618ms/step - loss: 1.3361\n","Epoch 13/20\n","38/38 [==============================] - 24s 620ms/step - loss: 1.2804\n","Epoch 14/20\n","38/38 [==============================] - 24s 619ms/step - loss: 1.2298\n","Epoch 15/20\n","38/38 [==============================] - 23s 615ms/step - loss: 1.1791\n","Epoch 16/20\n","38/38 [==============================] - 23s 616ms/step - loss: 1.1321\n","Epoch 17/20\n","38/38 [==============================] - 23s 615ms/step - loss: 1.0862\n","Epoch 18/20\n","38/38 [==============================] - 23s 615ms/step - loss: 1.0433\n","Epoch 19/20\n","38/38 [==============================] - 24s 632ms/step - loss: 1.0013\n","Epoch 20/20\n","38/38 [==============================] - 24s 622ms/step - loss: 0.9642\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa8373e3e10>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"6hhAWPgRX96V"},"source":["Once we have a trained model, we can simulate new text by making predictions about the next character and then drawing characters in proportion to the predicted probabilities. And then simple repeat that process over and over, each time drawing the next character."]},{"cell_type":"code","metadata":{"id":"IMpJwYSsZSoc","executionInfo":{"status":"ok","timestamp":1606019753847,"user_tz":300,"elapsed":629,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["def draw_char(probs):\n","    probs = np.asarray(probs).astype('float64')\n","    if sum(probs) != 1.0:\n","      probs = probs / np.sum(probs)\n","    draw = np.random.choice(range(len(probs)) , p=probs) \n","    #instead of picking the highest nunber, we take a random draw\n","    return draw\n","\n","def sample_text(model, sample_length=100):\n","    start = np.random.randint(0, len(text) - maxlen - 1)\n","    sequence = text[start: start + maxlen]\n","  \n","    x_preds = np.zeros((sample_length, maxlen, len(chars)))\n","    for i in range(sample_length):\n","        for t, char in enumerate(sequence[-maxlen:]):\n","            x_preds[i, t, char_indices[char]] = 1.\n","\n","        preds = model.predict(np.expand_dims(x_preds[i,:,:], axis=0), verbose=0)[0]\n","        next_index = draw_char(preds) #append the randomly drawn output as next_index\n","        next_char = indices_char[next_index]\n","\n","        sequence += next_char\n","    return sequence"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHD5iDlHayL7","executionInfo":{"status":"ok","timestamp":1606019777234,"user_tz":300,"elapsed":20980,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["sim = sample_text(char_rnn,sample_length=500) "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOP0ljRtOEmp","executionInfo":{"status":"ok","timestamp":1606019780888,"user_tz":300,"elapsed":342,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"ac243f61-85a4-48ce-dacf-bc059acc7505"},"source":["print(sim)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["he devil.\n","  LADY MACBETH. O proper stuff boust my had, silley. Come,\n","    Her will and Fit.\n","  MACDUFF. Als me. \n","  LORSS. And me what agains.\n","  DOCTOR. Their freaces thene?\n","  MACBETH. [Wes her arm-\n","  SIWAND dEITCHPFISSTON   BE HOP DoWoss him newfill to ar. I bey, my lord,\n","    say all of and scrat's roudies: thee stath,\n","    Which candroms withhen may,\n","    Of 'conquo'll hairs thee thuse about, the\n","    biveous undee to be not tomantent; me venest hatrine shead,\n","    Our 'tis ous see of is sence,\n","    Why does his wood. Bom comy, shy most the\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Aj4kXg4BTbOc"},"source":["Notice that we can do pretty well to learn the typical statistical patterns of this text and then simulate new text that appears to be very similar to legitimate Shakespeare. \n","\n","But just a caution - we can also do pretty well with a much simpler method (Markov model): http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139\n","\n","So the lesson is to try something simple before jumping right in to deep learning."]},{"cell_type":"markdown","metadata":{"id":"n5IE5xprp3RS"},"source":["## Exercise"]},{"cell_type":"markdown","metadata":{"id":"HoN_s6nQsDdn"},"source":["In this example, we're going to use an RNN for sequence classification. The task we'll set up is to generate a training set of randomized strings, and train our model to detect whether a string contains any vowels."]},{"cell_type":"markdown","metadata":{"id":"Isy5RPDdsTYT"},"source":["First, we'll create a training dataset of short randomized character sequences and the corresponding label of whether or not they contain at least one vowel."]},{"cell_type":"code","metadata":{"id":"hE6C-Xl6p5W7","executionInfo":{"status":"ok","timestamp":1606058363439,"user_tz":300,"elapsed":493,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["import string"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"CI7QA2Ewp-ZJ","executionInfo":{"status":"ok","timestamp":1606058662252,"user_tz":300,"elapsed":343,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["def contains_vowels(sequence):\n","  vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n","  return any([vowel in list(sequence) for vowel in vowels])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZ9cEhMrqtoG","executionInfo":{"status":"ok","timestamp":1606058821749,"user_tz":300,"elapsed":442,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"13855e43-71fb-4789-a34b-ff3012a11eb5"},"source":["contains_vowels(\"gradient\")"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"EwBEUPYwp9Z0","executionInfo":{"status":"ok","timestamp":1606060342319,"user_tz":300,"elapsed":537,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["sequences = []\n","labels = []\n","for i in range(1000):\n"," char_list = np.random.choice( list(string.ascii_lowercase), size = 5, replace=True)\n"," seq = \"\".join(char_list)\n"," sequences.append(seq)\n"," labels.append(int(contains_vowels(seq)))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMU3UMHYrkej","executionInfo":{"status":"ok","timestamp":1606060795718,"user_tz":300,"elapsed":337,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"d51f9f55-c12f-4dd6-967e-40de02493bd8"},"source":["sequences[0:5]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['qcdyy', 'hpbbu', 'vylff', 'sfjbp', 'wvtzo']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"IkJXdy5krgHn","executionInfo":{"status":"ok","timestamp":1606061101065,"user_tz":300,"elapsed":386,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["df = pd.DataFrame({\"sequence\": sequences, \"label\":labels})"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"ubAQf53Dr8zy","executionInfo":{"status":"ok","timestamp":1606061102555,"user_tz":300,"elapsed":374,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"1bfb3ba4-5aef-49e8-b85a-abba7ba1830c"},"source":["df.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sequence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>qcdyy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hpbbu</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vylff</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sfjbp</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wvtzo</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sequence  label\n","0    qcdyy      0\n","1    hpbbu      1\n","2    vylff      0\n","3    sfjbp      0\n","4    wvtzo      1"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"2xkX8Xa8sfID"},"source":["Next, set up and train an RNN (of any type) to solve this task. What preprocessing will you need to do first on the raw data in order to prepare it for the network?"]},{"cell_type":"code","metadata":{"id":"U5mAfC-vyF6g","executionInfo":{"status":"ok","timestamp":1606062504054,"user_tz":300,"elapsed":364,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["# Data Preprocessing\n","# your code here"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"6M4Sj4XHr9hj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606071663333,"user_tz":300,"elapsed":404,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"84eb9a3c-bd8e-4298-c02b-efa744729095"},"source":["txt_chars = sorted(list(set(text))) #vocabulary set\n","print('total chars:', len(txt_chars))\n","txt_char_indices = dict((c, i) for i, c in enumerate(txt_chars))"],"execution_count":76,"outputs":[{"output_type":"stream","text":["total chars: 75\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5gvolVZwwe6","executionInfo":{"status":"ok","timestamp":1606063718373,"user_tz":300,"elapsed":706,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"ff876fd9-686e-4f26-bcfe-6f8440a02dc5"},"source":["txt_maxlen = 5\n","step = 1\n","txt_sub_sequences = []\n","txt_label = []\n","for i in range(0, len(text) - txt_maxlen, step): #i is the 1st word, maxlen is the input length;\n","    #transform to lowercase\n","    seq = text[i: i + txt_maxlen].lower()\n","    txt_sub_sequences.append(seq) #txt_sub_sequences is the input characters;\n","    txt_label.append(int(contains_vowels(seq))) #label is using function: contains_vowels;\n","print('nb txt_sub_sequences:', len(txt_sub_sequences))\n","print('nb txt_label:', len(txt_label))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["nb txt_sub_sequences: 116134\n","nb txt_label: 116134\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UiMCe9Wxx-Sf","executionInfo":{"status":"ok","timestamp":1606065021492,"user_tz":300,"elapsed":4376,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["#split training set and test set\n","training_ix = np.random.choice( range(0,len(txt_label)), size=int(len(txt_label)*0.6), replace=False)\n","test_ix = [i for i in range(0,len(txt_label)) if i not in training_ix]\n","####\n","training_txt_sub_sequences = np.array(txt_sub_sequences)[training_ix]\n","test_txt_sub_sequences = np.array(txt_sub_sequences)[test_ix]\n","training_txt_label = np.array(txt_label)[training_ix]\n","test_txt_label = np.array(txt_label)[test_ix]"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szeeVEnU5Oli","executionInfo":{"status":"ok","timestamp":1606070730916,"user_tz":300,"elapsed":471,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"4f3799c3-564f-4445-d08c-d9527bcf2639"},"source":["print(\"training_txt_label:\",training_txt_label[0:5])\n","print(\"training_txt_sub_sequences\",training_txt_sub_sequences[0:5])"],"execution_count":74,"outputs":[{"output_type":"stream","text":["training_txt_label: [1 0 0 1 1]\n","training_txt_sub_sequences ['deed,' '.\\n   ' 'n!\\n  ' '   i ' 'pon t']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Og8gtSgHslED","executionInfo":{"status":"ok","timestamp":1606065211055,"user_tz":300,"elapsed":315,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["# Model setup and training\n","# your code here"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrJPh9s8S71S","executionInfo":{"status":"ok","timestamp":1606071691664,"user_tz":300,"elapsed":608,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["X_txt = np.zeros((len(training_txt_sub_sequences), txt_maxlen, len(txt_chars)), dtype=np.uint8 ) \n","# X: input dimension * dim of every input * character set (vocabulary set);\n","# 可以理解为有个matrix，每一行是一个输入，列数代表每个输入有多少字符，而第三维度即每个字符又以one-hot encoder表示\n","for i, seq in enumerate(training_txt_sub_sequences):\n","    for t, char in enumerate(seq): #t代表40个字符中已经遍历到哪个字符了\n","        X_txt[i, t, txt_char_indices[char]] = 1"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrV6--LgVTu5","executionInfo":{"status":"ok","timestamp":1606071883290,"user_tz":300,"elapsed":514,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["Y_txt = training_txt_label"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSLXwJvJszDu","executionInfo":{"status":"ok","timestamp":1606075467931,"user_tz":300,"elapsed":492,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["vowel_rnn = Sequential()\n","vowel_rnn.add(tfkl.LSTM(128, input_shape=(txt_maxlen, len(txt_chars))))\n","#vowel_rnn.add(tfkl.Dense(len(txt_chars),activation=\"softmax\"))\n","vowel_rnn.add(tfkl.Dense(1,activation=\"sigmoid\"))"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tdk3FBkojUJ7","executionInfo":{"status":"ok","timestamp":1606075469288,"user_tz":300,"elapsed":367,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"cdfb87fb-bfbc-4062-ff30-355e699def12"},"source":["vowel_rnn.summary()"],"execution_count":102,"outputs":[{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_5 (LSTM)                (None, 128)               104448    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 104,577\n","Trainable params: 104,577\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vypLaJXdfQrK","executionInfo":{"status":"ok","timestamp":1606075673601,"user_tz":300,"elapsed":356,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}}},"source":["vowel_rnn.compile(loss='binary_crossentropy', optimizer=tfk.optimizers.RMSprop(lr=0.01), metrics=['acc'])\n","# if you set the wrong loss function, for example, loss=\"categorical_crossentropy\", then the loss will not move any little bit\n","# To use \"categorical_crossentropy\" and \"softmax\", you need to transform label={0,1} or {1,0} instead of label=0 or 1\n","### because \"softmax\" will finally give you a y_predicted={0.25,0.25,0.4,0.1} which add up to 1 "],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcqX-cuWfcxw","executionInfo":{"status":"ok","timestamp":1606075735806,"user_tz":300,"elapsed":61025,"user":{"displayName":"Jenny Sun","photoUrl":"","userId":"01397775836505407150"}},"outputId":"395074ea-a646-4da1-83aa-ba439509a64a"},"source":["results =  vowel_rnn.fit(X_txt,Y_txt, epochs=10, batch_size=1024)"],"execution_count":106,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","69/69 [==============================] - 6s 84ms/step - loss: 0.1095 - acc: 0.9655\n","Epoch 2/10\n","69/69 [==============================] - 6s 83ms/step - loss: 0.0053 - acc: 0.9987\n","Epoch 3/10\n","69/69 [==============================] - 6s 84ms/step - loss: 5.0285e-05 - acc: 1.0000\n","Epoch 4/10\n","69/69 [==============================] - 6s 86ms/step - loss: 0.0117 - acc: 0.9983\n","Epoch 5/10\n","69/69 [==============================] - 6s 85ms/step - loss: 9.3562e-06 - acc: 1.0000\n","Epoch 6/10\n","69/69 [==============================] - 6s 84ms/step - loss: 7.7076e-07 - acc: 1.0000\n","Epoch 7/10\n","69/69 [==============================] - 6s 84ms/step - loss: 9.2217e-08 - acc: 1.0000\n","Epoch 8/10\n","69/69 [==============================] - 6s 84ms/step - loss: 1.7327e-08 - acc: 1.0000\n","Epoch 9/10\n","69/69 [==============================] - 6s 83ms/step - loss: 7.9029e-09 - acc: 1.0000\n","Epoch 10/10\n","69/69 [==============================] - 6s 85ms/step - loss: 5.1321e-09 - acc: 1.0000\n"],"name":"stdout"}]}]}